'''This class contains fields and methods to extract weather data from desiredgeographic locations.'''import osimport requestsfrom bs4 import BeautifulSoupimport pandas as pdimport pickle as pklimport jsonclass WeatherData():        def __init__(self, noaa_api_key, city_code):                '''        Description:            Initialize CAMP User with relevant parameters                Inputs:            noaa_api_key: str                NOAA API key            city_code: str                city code for snow data                Outputs:            N/A        '''                self.noaa_api_key = noaa_api_key        self.city_code = city_code            def get_snow_table(self):                '''        Description:            Get snow totals by year from html                Inputs:            N/A                Outputs:            snow_table: pandas dataframe                table containing snow data        '''                # Get table from page        snow_url = os.path.join('https://www.weather.gov', self.city_code,                         'historicalSnow')        page = requests.get(snow_url)        soup = BeautifulSoup(page.text, 'lxml')        table = soup.find('table')                # Get headers        headers = []        for i in table.find_all('th'):            title = i.text            title = title.replace('\n', '')            if 'Min' in title or 'Max' in title or 'Mean' in title:                continue            headers.append(title)                # Create dataframe        snow_table = pd.DataFrame(columns = headers)                # Populate dataframe        for j in table.find_all('tr')[1:]:            row_data = j.find_all('td')            row = [i.text for i in row_data]            if row[0] == 'T':                break            length = len(snow_table)            snow_table.loc[length] = row                    return snow_table            def clean_snow_table(self, snow_table):                '''        Description:            Clean up snow table                Inputs:            snow_table: pandas dataframe                Outputs:            snow_table: pandas dataframe                cleaned table containing snow data        '''                # Get rid of any rows that are missing data (this year)        delete_rows = []        for r in range(len(snow_table)):            for c in range(len(snow_table.columns)):                data = snow_table.iloc[r, c]                if data == '\xa0':                    delete_rows.append(r)                    break                        snow_table = snow_table.drop(labels=delete_rows, axis=0)                # Get rid of all columns that aren'y year or snowfall total        keep_cols = ['Year', 'Season']        delete_cols = []        for c in snow_table.columns:            if c not in keep_cols:                delete_cols.append(c)                        snow_table = snow_table.drop(labels=delete_cols, axis=1)                # Convert to int/float        for r in range(len(snow_table)):            year = snow_table.iloc[r, 0].split('-')[0]            snow_table['Year'][r] = year                    snow_table['Year'] = snow_table['Year'].astype('int')        snow_table['Season'] = snow_table['Season'].astype('float')                return snow_table        def get_city_data_noaa(self, station_id, station_name, start_year, end_year):                '''        Description:            Get city data from NOAA API                Inputs:            station_id: str                station whose weather to access            station_name: str                location of station            start_year: int                year to start grabbing data            end_year: int                year to end grabbing data                Outputs:            N/A: saves json files to data repo        '''                # List of fields we want from GHCND dataset        # https://www.ncei.noaa.gov/pub/data/ghcn/daily/readme.txt        fields = ['PRCP', # Precipitation (tenths of mm)                  'SNOW', # Snowfall (mm)                  'SNWD', # Snow depth (mm)                  'TMAX', # Maximum temperature (tenths of degrees C)                  'TMIN', # Minimum temperature (tenths of degrees C)                  'ACMC', # Average cloudiness midnight to midnight from 30-second ceilometer data (percent)                  'ACMH', # Average cloudiness midnight to midnight from manual observations (percent)                  'ADPT', # Average Dew Point Temperature for the day (tenths of degrees C)                  'ASLP', # Average Sea Level Pressure for the day (hPa * 10)                  'ASTP', # Average Station Level Pressure for the day (hPa * 10)                  'AWDR', # Average daily wind direction (degrees)                  'AWND', # Average daily wind speed (tenths of meters per second)                  'EVAP', # Evaporation of water from evaporation pan (tenths of mm)                  'FRGB', # Base of frozen ground layer (cm)                  'FRGT', # Top of frozen ground layer (cm)                  'PSUN', # Daily percent of possible sunshine (percent)                  'RHAV', # Average relative humidity for the day (percent)                  'RHMN', # Minimum relative humidity for the day (percent)                  'RHMX', # Maximum relative humidity for the day (percent)                  'TAVG', # Average temperature (tenths of degrees C)                  'TSUN', # Daily total sunshine (minutes)                  'WSFG'] # WSFG = Peak gust wind speed (tenths of meters per second)                for year in range(start_year, end_year):                        year = str(year)                        # Need to be careful because NOAA has 1000 limit for query            for f in fields:                url = 'https://www.ncdc.noaa.gov/cdo-web/api/' + \                    'v2/data?datasetid=GHCND&datatypeid=' + f + \                    '&limit=1000&stationid=' + station_id + \                    '&startdate=' + year + '-01-01&enddate=' + year + '-12-31'                r = requests.get(url, headers={'token':self.noaa_api_key})                json_data = r.json()                                # Skip if empty                if len(json_data.keys()) > 0:                                    # Save dataframe otherwise                    save_loc = os.path.join(os.getcwd(), 'api_data')                    if not os.path.isdir(save_loc):                        os.mkdir(save_loc)                    fname = station_name + '_' + f + '_' + year + '.json'                    with open(os.path.join(save_loc, fname), 'w') as f:                        json.dump(json_data, f)                            def get_city_data_open_meteo(self, lat, lon, name, start_year, end_year):                '''        Description:            Get city data from Open-Meteo API                Inputs:            lat: float                city latitude            lon: float                city longitude            name: str                city name            start_year: int                year to start grabbing data            end_year: int                year to end grabbing data                Outputs:            N/A: saves json files to data repo        '''                # List of fields we want from historical dataset        # https://open-meteo.com/en/docs/historical-weather-api#api_form        fields = ['temperature_2m',                  'relativehumidity_2m',                  'surface_pressure',                  'snowfall',                  'cloudcover_low',                  'cloudcover_mid',                  'cloudcover_high',                  'shortwave_radiation',                  'direct_radiation',                  'diffuse_radiation',                  'windspeed_10m',                  'soil_temperature_0_to_7cm']                # Build fields string for API query        fields_str = ''        for f in fields:            fields_str = fields_str + f + ','        fields_str = fields_str[0:-1]        for year in range(start_year, end_year):                        # Get info for API query            year = str(year)            sd = year + '-01-01'            ed = year + '-12-31'            url = 'https://archive-api.open-meteo.com/v1/archive?latitude=' + \                str(lat) + '&longitude=' + str(lon) + \                '&start_date=' + sd + '&end_date=' + ed + \                '&hourly=' + fields_str + '&timezone=America%2FNew_York'                            # Make query            r = requests.get(url)                        # Check for error code            if r.status_code != 200:                print('Error code in API query.')                continue                        # Convert to json            json_data = r.json()                        # Skip if empty            if len(json_data.keys()) > 0:                            # Save dataframe otherwise                save_loc = os.path.join(os.getcwd(), 'api_data')                if not os.path.isdir(save_loc):                    os.mkdir(save_loc)                fname = name + '_' + year + '.json'                with open(os.path.join(save_loc, fname), 'w') as f:                    json.dump(json_data, f)                    if __name__ == "__main__":        from matplotlib import pyplot as plt        # Get some folder info    pwd = os.getcwd()    save_loc = os.path.join(pwd, 'figs')    if not os.path.isdir(save_loc):        os.mkdir(save_loc)        # Initialize WeatherData object    obj = WeatherData('WFOckfmIedXAYNpnsZkatzGzyFkxUvWd', 'btv')        # Get Burlington snow data and plot    if not os.path.isfile(os.path.join(pwd, 'figs', 'btv_snowfall_clean.png')):                # Get Burlington snow data                snow_table = obj.get_snow_table()        clean_snow_table = obj.clean_snow_table(snow_table)                # Plot uncleaned Burlington snow data        fig, ax = plt.subplots()        x = list(snow_table['Year'])        y = list(snow_table['Season'].astype('float'))        ax.plot(x, y)        my_xticks = ax.get_xticks()        ax.set_xticks([my_xticks[0], my_xticks[round(my_xticks[-1] / 2)],                       my_xticks[-1]], visible=True, rotation=45)        ax.set_xlabel('Year')        ax.set_ylabel('Snowfall [in]')        ax.set_title('Burlington, VT Yearly Snowfall: Uncleaned')        ax.grid()        fig.savefig(os.path.join(save_loc, 'btv_snowfall_unclean.png'), dpi=600)                # Plot cleaned Burlington snow data        fig, ax = plt.subplots()        x = list(clean_snow_table['Year'])        y = list(clean_snow_table['Season'].astype('float'))        ax.plot(x, y)        ax.set_xlabel('Year')        ax.set_ylabel('Snowfall [in]')        ax.set_title('Burlington, VT Yearly Snowfall: Cleaned')        ax.grid()        fig.savefig(os.path.join(save_loc, 'btv_snowfall_clean.png'), dpi=600)        # Get data from different Vermont cities - NOAA    station_ids = ['GHCND:US1VTCH0005', # Burlington                   'GHCND:USC00435273', # Montpelier                   'GHCND:USC00436995', # Rutland                   'GHCND:US1NHCH0002', # Brattleboro                   'GHCND:USC00435542', # Newport                   'GHCND:USC00435416'] # Mt. Mansfield Nose    station_names = ['Burlington',                     'Montpelier',                     'Rutland',                     'Brattleboro',                     'Newport',                     'Mt_Mansfield']                      for (si, sn) in zip(station_ids, station_names):        obj.get_city_data(si, sn, 1960, 2023)        # Get data from different Vermont cities - Open-Meteo    latlon = [[44.48, -73.21], # Burlington              [44.26, -72.58], # Montpelier              [43.61, -72.97], # Rutland              [42.85, -72.56], # Brattleboro              [44.95, -72.31], # Newport              [44.47, -72.68]] # Stowe    station_names = ['Burlington',                     'Montpelier',                     'Rutland',                     'Brattleboro',                     'Newport',                     'Stowe']                      for (ll, sn) in zip(latlon, station_names):        obj.get_city_data_open_meteo(ll[0], ll[1], sn, 1960, 2023)                                    